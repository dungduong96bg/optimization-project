{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba45e010",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97ca8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7765d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    Zs = Z - np.max(Z, axis=1, keepdims=True)\n",
    "    expZ = np.exp(Zs)\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69c278c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(W, X, Y, eps=1e-12):\n",
    "    P = softmax(X @ W)\n",
    "    loss = -np.mean(np.sum(Y * np.log(P + eps), axis=1))\n",
    "    return loss, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96220a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_softmax(X, Y, lr=0.05, epochs=100, shuffle=True, seed=42):\n",
    "    \"\"\"\n",
    "    X: (n,d)\n",
    "    Y: (n,K) one-hot\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    K = Y.shape[1]\n",
    "    W = np.zeros((d, K))\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.arange(n)\n",
    "        if shuffle:\n",
    "            rng.shuffle(idx)\n",
    "\n",
    "        for i in idx:\n",
    "            xi = X[i:i+1, :]              # (1,d)\n",
    "            yi = Y[i:i+1, :]              # (1,K)\n",
    "\n",
    "            pi = softmax(xi @ W)          # (1,K)\n",
    "            dW = xi.T @ (pi - yi)         # (d,K)\n",
    "            W -= lr * dW\n",
    "\n",
    "        loss, _ = cross_entropy(W, X, Y)\n",
    "        print(f\"[SGD] epoch {epoch+1} loss={loss:.6f}\")\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02e1457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W):\n",
    "    P = softmax(X @ W)\n",
    "    y_pred = np.argmax(P, axis=1)\n",
    "    return y_pred, P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94877e8b",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "566a512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load data ----\n",
    "X_tr = pd.read_csv(\n",
    "    r\"C:\\Users\\admin\\Documents\\Study\\Master\\Optimization\\optimization-project\\Data\\Train_test\\X_train.csv\"\n",
    ").drop(columns=[\"strata\"], errors=\"ignore\").values\n",
    "Y_tr = pd.read_csv(\n",
    "    r\"C:\\Users\\admin\\Documents\\Study\\Master\\Optimization\\optimization-project\\Data\\Train_test\\y_train.csv\"\n",
    ").values.ravel()\n",
    "X_te = pd.read_csv(\n",
    "    r\"C:\\Users\\admin\\Documents\\Study\\Master\\Optimization\\optimization-project\\Data\\Train_test\\X_test.csv\"\n",
    ").drop(columns=[\"strata\"], errors=\"ignore\").values\n",
    "\n",
    "Y_te = pd.read_csv(\n",
    "    r\"C:\\Users\\admin\\Documents\\Study\\Master\\Optimization\\optimization-project\\Data\\Train_test\\y_test.csv\"\n",
    ").values.ravel()\n",
    "\n",
    "# Y_tr_raw, Y_te_raw là nhãn 1D\n",
    "y_tr = Y_tr.copy()\n",
    "y_te = Y_te.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7468e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALE FEATURES \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr)\n",
    "X_te = scaler.transform(X_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ed9722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse_output=False)\n",
    "Y_tr = enc.fit_transform(y_tr.reshape(-1,1))\n",
    "Y_te = enc.transform(y_te.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "484a4709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SGD] epoch 1 loss=0.808759\n",
      "[SGD] epoch 2 loss=0.731033\n",
      "[SGD] epoch 3 loss=0.924207\n",
      "[SGD] epoch 4 loss=0.736483\n",
      "[SGD] epoch 5 loss=0.871532\n",
      "[SGD] epoch 6 loss=0.805170\n",
      "[SGD] epoch 7 loss=0.739757\n",
      "[SGD] epoch 8 loss=0.790381\n",
      "[SGD] epoch 9 loss=0.746348\n",
      "[SGD] epoch 10 loss=0.791290\n",
      "[SGD] epoch 11 loss=0.821354\n",
      "[SGD] epoch 12 loss=0.897502\n",
      "[SGD] epoch 13 loss=0.779056\n",
      "[SGD] epoch 14 loss=0.779089\n",
      "[SGD] epoch 15 loss=0.825194\n",
      "[SGD] epoch 16 loss=0.724977\n",
      "[SGD] epoch 17 loss=0.756171\n",
      "[SGD] epoch 18 loss=0.771898\n",
      "[SGD] epoch 19 loss=0.793138\n",
      "[SGD] epoch 20 loss=0.870974\n",
      "[SGD] epoch 21 loss=0.669558\n",
      "[SGD] epoch 22 loss=0.759083\n",
      "[SGD] epoch 23 loss=0.769834\n",
      "[SGD] epoch 24 loss=0.792464\n",
      "[SGD] epoch 25 loss=0.809128\n",
      "[SGD] epoch 26 loss=0.733155\n",
      "[SGD] epoch 27 loss=0.775169\n",
      "[SGD] epoch 28 loss=0.825575\n",
      "[SGD] epoch 29 loss=0.797680\n",
      "[SGD] epoch 30 loss=0.751542\n",
      "[SGD] epoch 31 loss=0.780000\n",
      "[SGD] epoch 32 loss=0.715111\n",
      "[SGD] epoch 33 loss=0.953440\n",
      "[SGD] epoch 34 loss=0.754851\n",
      "[SGD] epoch 35 loss=0.780875\n",
      "[SGD] epoch 36 loss=0.801365\n",
      "[SGD] epoch 37 loss=0.698700\n",
      "[SGD] epoch 38 loss=0.811502\n",
      "[SGD] epoch 39 loss=0.785921\n",
      "[SGD] epoch 40 loss=0.855833\n",
      "[SGD] epoch 41 loss=0.808624\n",
      "[SGD] epoch 42 loss=0.903573\n",
      "[SGD] epoch 43 loss=0.800414\n",
      "[SGD] epoch 44 loss=0.756748\n",
      "[SGD] epoch 45 loss=0.829500\n",
      "[SGD] epoch 46 loss=0.952618\n",
      "[SGD] epoch 47 loss=0.751687\n",
      "[SGD] epoch 48 loss=0.818555\n",
      "[SGD] epoch 49 loss=0.806027\n",
      "[SGD] epoch 50 loss=0.761229\n",
      "[SGD] epoch 51 loss=0.802524\n",
      "[SGD] epoch 52 loss=0.859128\n",
      "[SGD] epoch 53 loss=0.927406\n",
      "[SGD] epoch 54 loss=0.720989\n",
      "[SGD] epoch 55 loss=0.806852\n",
      "[SGD] epoch 56 loss=0.780362\n",
      "[SGD] epoch 57 loss=0.842399\n",
      "[SGD] epoch 58 loss=0.792902\n",
      "[SGD] epoch 59 loss=0.914693\n",
      "[SGD] epoch 60 loss=0.822129\n",
      "[SGD] epoch 61 loss=0.848009\n",
      "[SGD] epoch 62 loss=0.869600\n",
      "[SGD] epoch 63 loss=0.794404\n",
      "[SGD] epoch 64 loss=0.778220\n",
      "[SGD] epoch 65 loss=0.808061\n",
      "[SGD] epoch 66 loss=0.755329\n",
      "[SGD] epoch 67 loss=0.802007\n",
      "[SGD] epoch 68 loss=0.714080\n",
      "[SGD] epoch 69 loss=0.744706\n",
      "[SGD] epoch 70 loss=0.803638\n",
      "[SGD] epoch 71 loss=0.790040\n",
      "[SGD] epoch 72 loss=0.721857\n",
      "[SGD] epoch 73 loss=0.744913\n",
      "[SGD] epoch 74 loss=0.765822\n",
      "[SGD] epoch 75 loss=0.748235\n",
      "[SGD] epoch 76 loss=0.791056\n",
      "[SGD] epoch 77 loss=0.849075\n",
      "[SGD] epoch 78 loss=0.779997\n",
      "[SGD] epoch 79 loss=0.902615\n",
      "[SGD] epoch 80 loss=0.811040\n",
      "[SGD] epoch 81 loss=0.782948\n",
      "[SGD] epoch 82 loss=0.766546\n",
      "[SGD] epoch 83 loss=0.714806\n",
      "[SGD] epoch 84 loss=0.765967\n",
      "[SGD] epoch 85 loss=0.788563\n",
      "[SGD] epoch 86 loss=0.763874\n",
      "[SGD] epoch 87 loss=0.878669\n",
      "[SGD] epoch 88 loss=0.858437\n",
      "[SGD] epoch 89 loss=0.776475\n",
      "[SGD] epoch 90 loss=0.751591\n",
      "[SGD] epoch 91 loss=0.802374\n",
      "[SGD] epoch 92 loss=0.751668\n",
      "[SGD] epoch 93 loss=0.951976\n",
      "[SGD] epoch 94 loss=0.743657\n",
      "[SGD] epoch 95 loss=0.828773\n",
      "[SGD] epoch 96 loss=0.747962\n",
      "[SGD] epoch 97 loss=0.765957\n",
      "[SGD] epoch 98 loss=0.738684\n",
      "[SGD] epoch 99 loss=0.728806\n",
      "[SGD] epoch 100 loss=0.836481\n",
      "Train acc: 0.7236917768832662\n",
      "Test  acc: 0.7206896551724138\n"
     ]
    }
   ],
   "source": [
    "W = sgd_softmax(X_tr, Y_tr, lr=0.05, epochs=100)\n",
    "\n",
    "# Predict\n",
    "y_pred_tr, _ = predict(X_tr, W)\n",
    "y_pred_te, _ = predict(X_te, W)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train acc:\", accuracy_score(y_tr, y_pred_tr))\n",
    "print(\"Test  acc:\", accuracy_score(y_te, y_pred_te))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
