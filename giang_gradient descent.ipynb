{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75875ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax\n",
    "def softmax(Z):\n",
    "    Zs = Z - np.max(Z, axis=1, keepdims=True)  # ổn định số học\n",
    "    expZ = np.exp(Zs)\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef58e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function\n",
    "def cross_entropy(W, X, Y, epsilon=1e-12):\n",
    "    P = softmax(X @ W)  # (n,K)\n",
    "    loss = -np.mean(np.sum(Y * np.log(P + epsilon), axis=1))\n",
    "    return loss, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "def gd_softmax(X, Y, lr=0.1, epochs=500, tol=1e-7, verbose=True):\n",
    "    n, d = X.shape\n",
    "    K = Y.shape[1]\n",
    "    W = np.zeros((d, K))\n",
    "    history = []\n",
    "\n",
    "    for t in range(1, epochs+1):\n",
    "        loss, P = cross_entropy(W, X, Y)\n",
    "        history.append(loss)\n",
    "\n",
    "        # Gradient\n",
    "        dW = (X.T @ (P - Y)) / n\n",
    "\n",
    "        # Update\n",
    "        W_new = W - lr * dW\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(W_new - W) < tol:\n",
    "            W = W_new\n",
    "            if verbose:\n",
    "                print(f\"[Softmax] Early stop at epoch {t}, loss={loss:.6f}\")\n",
    "            break\n",
    "\n",
    "        W = W_new\n",
    "        if verbose and (t == 1 or t % 50 == 0):\n",
    "            print(f\"[Softmax] epoch {t:4d} loss={loss:.6f}\")\n",
    "\n",
    "    return W, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict ---\n",
    "def predict(X, W):\n",
    "   P = softmax(X @ W)       # X: (n,d), W: (d,K) -> P: (n,K)\n",
    "   y_pred = np.argmax(P, axis=1)\n",
    "   return y_pred, P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb78f901",
   "metadata": {},
   "source": [
    "## Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2644f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load data ----\n",
    "X_tr = pd.read_csv(\n",
    "    r\"C:\\Users\\admin\\Documents\\Study\\Master\\Optimization\\optimization-project\\Data\\Train_test\\X_train.csv\"\n",
    ").drop(columns=[\"strata\"], errors=\"ignore\").values\n",
    "Y_tr = pd.read_csv(\n",
    "    r\"C:\\Users\\admin\\Documents\\Study\\Master\\Optimization\\optimization-project\\Data\\Train_test\\y_train.csv\"\n",
    ").values.ravel()\n",
    "X_te = pd.read_csv(\n",
    "    r\"C:\\Users\\admin\\Documents\\Study\\Master\\Optimization\\optimization-project\\Data\\Train_test\\X_test.csv\"\n",
    ").drop(columns=[\"strata\"], errors=\"ignore\").values\n",
    "\n",
    "Y_te = pd.read_csv(\n",
    "    r\"C:\\Users\\admin\\Documents\\Study\\Master\\Optimization\\optimization-project\\Data\\Train_test\\y_test.csv\"\n",
    ").values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04499ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALE FEATURES \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr)\n",
    "X_te = scaler.transform(X_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse_output=False)\n",
    "Y_train = enc.fit_transform(Y_tr.reshape(-1,1))\n",
    "Y_test  = enc.transform(Y_te.reshape(-1,1))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c07ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Softmax] epoch    1 loss=1.098612\n",
      "[Softmax] epoch   50 loss=0.651533\n",
      "[Softmax] epoch  100 loss=0.610248\n",
      "[Softmax] epoch  150 loss=0.594145\n",
      "[Softmax] epoch  200 loss=0.585915\n",
      "[Softmax] epoch  250 loss=0.580960\n",
      "[Softmax] epoch  300 loss=0.577614\n",
      "[Softmax] epoch  350 loss=0.575162\n",
      "[Softmax] epoch  400 loss=0.573261\n",
      "[Softmax] epoch  450 loss=0.571729\n",
      "[Softmax] epoch  500 loss=0.570462\n",
      "Final train loss: 0.5704616087648411\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện với train\n",
    "W, history = gd_softmax(X_tr, Y_train, lr=0.1, epochs=500)\n",
    "\n",
    "# In loss cuối cùng\n",
    "print(\"Final train loss:\", history[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d404ab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.7722829212190915\n",
      "Test  acc: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr, P_tr = predict(X_tr, W)\n",
    "print(\"Train acc:\", (y_pred_tr == Y_tr).mean())\n",
    "\n",
    "y_pred_te, P_te = predict(X_te, W)\n",
    "print(\"Test  acc:\", (y_pred_te == Y_te).mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
